<!DOCTYPE html>
<head>
    <meta charset="utf-8" />
    <title>CraftsMan3D: High-fidelity Mesh Generation with 3D Native Generation
        and Interactive Geometry Refiner</title>
	<link rel="icon" type="image/x-icon" href="../assets/css/images/favicon.ico">
    <meta content="CraftsMan3D: High-fidelity Mesh Generation with 3D Native Generation
    and Interactive Geometry Refiner" name="description" />
    <meta content="summary" name="twitter:card" />
    <meta content="width=device-width, initial-scale=1" name="viewport" />
    <link href="static/css/template.css" rel="stylesheet" type="text/css" />
    <link href="static/css/my_style.css" rel="stylesheet" type="text/css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    
    <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js" type="text/javascript"></script>
    <script type="text/javascript">
        WebFont.load({
            google: {
                families: ["Lato:100,100italic,300,300italic,400,400italic,700,700italic,900,900italic", "Montserrat:100,100italic,200,200italic,300,300italic,400,400italic,500,500italic,600,600italic,700,700italic,800,800italic,900,900italic", "Ubuntu:300,300italic,400,400italic,500,500italic,700,700italic", "Changa One:400,400italic", "Open Sans:300,300italic,400,400italic,600,600italic,700,700italic,800,800italic", "Varela Round:400", "Bungee Shade:regular", "Roboto:300,regular,500"]
            }
        });
    </script>
    <script type="text/javascript">
        ! function (o, c) {
            var n = c.documentElement,
                t = " w-mod-";
            n.className += t + "js", ("ontouchstart" in o || o.DocumentTouch && c instanceof DocumentTouch) && (n.className += t + "touch")
        }(window, document);
    </script>
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <script type="text/javascript" src="static/js/zoom.js"></script>
    <script type="text/javascript" src="static/js/video_comparison.js"></script>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-MLDP9MKGC8"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-MLDP9MKGC8');
    </script>
    <script type="module" src="./static/js/model-viewer.min.js"></script>
</head>

<body>
    <div class="section hero nerf-_v2">
        <div class="container-2 nerf_header_v2 w-container">
            <h1 class="nerf_title_v2">CraftsMan3D:<br /> High-fidelity Mesh Generation with 3D Native Generation and Interactive Geometry Refiner</h1>
            <!-- <div class="nerf_subheader_v2"></div> -->
            <h1 class="nerf_affiliation_v2" style="font-size:24px;"><i class="fa fa-bullhorn" style="color:#F9423A"> </i>
                <font color="#F9423A"><b> We are continuing to grow, more models will be released in the next months !!!</b></font></h1>
            <div class="nerf_subheader_v2">
                <div>
                    <a href="https://wyysf-98.github.io/" target="_blank" class="nerf_authors_v2">Weiyu Li*<span
                            class="text-span_nerf"></span></a><sup> 1,2</sup>,&nbsp;&nbsp;
                    <h1 class="nerf_affiliation_v2">Jiarui Liu*</h1><sup> 1,2</sup>,&nbsp;&nbsp;
		            <h1 class="nerf_affiliation_v2">Hongyu Yan*</h1><sup> 1</sup>,&nbsp;&nbsp;
                    <a href="https://aruichen.github.io/" target="_blank" class="nerf_authors_v2">Rui Chen<span
                            class="text-span_nerf"></span></a><sup> 1</sup>,&nbsp;&nbsp;
                    <a href="https://yixunliang.github.io/" target="_blank" class="nerf_authors_v2">Yixun Liang<span
                        class="text-span_nerf"></span></a><sup> 1,2</sup>,&nbsp;&nbsp;
                    <a href="https://xuelin-chen.github.io/" target="_blank" class="nerf_authors_v2">Xuelin Chen<span
                            class="text-span_nerf"></span></a><sup> 3</sup>,&nbsp;&nbsp;
                    <a href="https://ece.hkust.edu.hk/pingtan" target="_blank" class="nerf_authors_v2">Ping Tan<span
                            class="text-span_nerf"></span></a><sup> 1,2</sup>,&nbsp;&nbsp;
                    <a href="https://www.xxlong.site/" target="_blank" class="nerf_authors_v2">Xiaoxiao Long†<span
                            class="text-span_nerf"></span></a><sup> 1,2</sup>
                </div>
                <div>
                    <h1 class="nerf_affiliation_v2"><sup>1 </sup>HKUST</h1>,
                    <h1 class="nerf_affiliation_v2"><sup>2 </sup>LightIllusions</h1>,
                    <h1 class="nerf_affiliation_v2"><sup>3 </sup>Adobe Research</h1>
                </div>

                <div class="external-link">
                    <a class="btn" href="https://arxiv.org/pdf/2405.14979" role="button" target="_blank">
                        <i class="ai ai-arxiv"></i> Arxiv </a>
                    <a class="btn" href="paper/paper.pdf" role="button" target="_blank">
                        <i class="fa fa-file-pdf"></i> Paper </a>
                    <a class="btn" href="https://huggingface.co/spaces/wyysf/CraftsMan3D" role="button" target="_blank">
                        <i class="fa-solid fa-chess-knight"></i> Demo (HF) </a> 
                    <a class="btn" href="http://algodemo.bj.lightions.top:24926" role="button" target="_blank">
                        <i class="fa-solid fa-chess-knight"></i> Demo (Local_bak) </a> 
                    <a class="btn" href="https://github.com/wyysf-98/CraftsMan3D" role="button" target="_blank" disabled>
                        <i class="fa-brands fa-github"></i> Code </a>
                    <a class="btn btn-large btn-light" href="https://www.youtube.com/watch?v=WhEs4tS4mGo" role="button" target="_blank" disabled>
                        <i class="fa-brands fa-youtube"></i> Video </a>
                </div>
                
            </div>
        </div>
    </div>
    <div class="white_section_nerf  w-container">
        <!-- <h2 class="grey-heading_nerf nerf_text">Acknowledgement</h2> -->
        <div class="grid-container-1">
	    <p> 
		    <strong>Acknowledgement: <a href="mailto:flybirdtian@gmail.com" target="_blank" class="nerf_authors_v2">Feipeng Tian</span></a>, <a href="mailto:sxwlttsd@gmail.com" target="_blank" class="nerf_authors_v2">Xiao Chen</span></a> from <a href="https://www.lightillusions.com/" target="_blank" class="nerf_authors_v2">LightIllusions</span></a>
                working on the algorithm generation of the texture part; <a href="mailto:wylm.ng@qq.com" target="_blank" class="nerf_authors_v2">Shihao Wu</a>, <a href="mailto:eescutwangzihao@163.com" target="_blank" class="nerf_authors_v2">Zihao Wang</a> from LightIllusions
                working for the data processing, including data cleaning and rendering;<br></strong>
	    </p>
        </div>
    </div>


    <div data-anchor="slide1" class="section nerf_section">
        <div class="w-container grey_container">
            <h2 class="grey-heading_nerf">Abstract</h2>
            <p class="paragraph-3 nerf_text nerf_results_text">
                We present a novel generative 3D modeling system, coined <font color="#36afe8"><b>CraftsMan3D</b></font>, which
                can generate high-fidelity 3D geometries with highly varied shapes, regular
                mesh topologies and detailed surfaces, and notably, allows for refining the
                geometry in an interactive manner. Despite the significant advancements
                in 3D generation, existing methods still struggle with lengthy optimization
                processes, irregular mesh topologies, noisy surfaces, and difficulties in 
                accommodating user edits, consequently impeding their widespread adoption
                and implementation in 3D modeling software. Our work is inspired by the
                craftsman, who usually roughs out the holistic figure of the work first and
                elaborate the surface details subsequently. Specifically, we employ a 3D
                native diffusion model, which operates on latent space learned from latent
                set-based 3D representations, to generate coarse geometries with regular
                mesh topology in seconds. In particular, this process takes as input a text
                prompt or a reference image, and leverages a powerful multi-view (MV)
                diffusion model to generate multiple views of the coarse geometry, which
                are fed into our MV-conditioned 3D diffusion model for generating the 3D
                geometry, significantly improving robustness and generalizability. Following
                that, a normal-based geometry refiner is used to significantly enhance the surface details. This refinement can be performed automatically, or inter-
                actively with user-supplied edits. Extensive experiments demonstrate that
                our method achieves high efficiency in producing superior-quality 3D assets
                compared to existing methods.
                <br>
                <!-- <img  src="assets/images/overview.png"> -->
            </p>
        </div>
    </div>


    <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">Image Conditioned 3D Native Diffusion Results</h2>
        <p class="myprompt nerf_text"> Some images are from 
            <a href="https://hyperhuman.deemos.com/rodin" target="_blank" class="nerf_authors_v2">Rodin<span
                class="text-span_nerf"></span></a>,
            <a href="https://www.tripo3d.ai/" target="_blank" class="nerf_authors_v2">Tripo<span
                class="text-span_nerf"></span></a>,
            <a href="https://nju-3dv.github.io/projects/Direct3D/" target="_blank" class="nerf_authors_v2">Direct3D<span
                class="text-span_nerf"></span></a>.
            </p>
        <div class="grid-container-4">
            <div>
                <p class="myprompt nerf_text"> Reference Image </p>
                <img src="assets/image_to_3d/monster.png">
            </div>
            <div>
                <p class="myprompt nerf_text"> Output Coarse Mesh </p>
                <model-viewer exposure="0.5" camera-controls enable-pan shadow-intensity="2" camera-orbit="0deg 75deg 150%" max-camera-orbit="auto auto 100%"
                src="assets/image_to_3d/monster_textured.glb">
                </model-viewer>
            </div>
            <div>
                <p class="myprompt nerf_text"> Reference Image </p>
                <img src="assets/image_to_3d/bug.png">
            </div>
            <div>
                <p class="myprompt nerf_text"> Output Coarse Mesh </p>
                <model-viewer exposure="0.5" camera-controls enable-pan shadow-intensity="2" camera-orbit="0deg 75deg 150%" max-camera-orbit="auto auto 100%"
                src="assets/image_to_3d/bug_textured.glb">
                </model-viewer>
            </div>
        </div>
        <div class="grid-container-4">
            <div>
                <img src="assets/image_to_3d/dragon.png">
            </div>
            <div>
                <model-viewer exposure="0.5" camera-controls enable-pan shadow-intensity="2" camera-orbit="0deg 75deg 150%" max-camera-orbit="auto auto 100%"
                src="assets/image_to_3d/dragon_textured.glb">
                </model-viewer>
            </div>
            <div>
                <img src="assets/image_to_3d/fac87a0ff51148859b16b8bfa7e9bfe0.png">
            </div>
            <div>
                <model-viewer exposure="0.5" camera-controls enable-pan shadow-intensity="2" camera-orbit="0deg 75deg 150%" max-camera-orbit="auto auto 100%"
                src="assets/image_to_3d/fac87a0ff51148859b16b8bfa7e9bfe0_textured.glb">
                </model-viewer>
            </div>
        </div>
        <div class="grid-container-1">
            <a class="mybtn" href="image-conditioned-3D-gallery_0.html" role="button">
             More Results </a>
        </div>
    </div>


    <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">Text Conditioned 3D Native Diffusion Results</h2>
        <div class="grid-container-4">
            <p class="myprompt nerf_text"> Leaning Tower <br /> of Pisa <br /> </p>
            <p class="myprompt nerf_text"> a marble bust of a fox head </p>
            <p class="myprompt nerf_text"> An astronaut <br /> in a space suit  </p>
            <p class="myprompt nerf_text"> Banana boss, <br />cute, hands and legs </p>
        </div>
        <div class="grid-container-4">
            <div class="model-block">
                <model-viewer exposure="0.5" camera-controls enable-pan shadow-intensity="2" camera-orbit="0deg 75deg 110%" max-camera-orbit="auto auto 200%"
                src="assets/text-to-3d/Leaning Tower of Pisa.glb">
                </model-viewer>
            </div>
            <div class="model-block"> 
                <model-viewer exposure="0.5" camera-controls enable-pan shadow-intensity="2" camera-orbit="0deg 75deg 110%" max-camera-orbit="auto auto 200%"
                src="assets/text-to-3d/a marble bust of a fox head.glb">
                </model-viewer>
            </div>
            <div class="model-block">
                <model-viewer exposure="0.5" camera-controls enable-pan shadow-intensity="2" camera-orbit="0deg 75deg 110%" max-camera-orbit="auto auto 200%"
                src="assets/text-to-3d/An astronaut in a space suit.glb">
                </model-viewer>
            </div>
            <div class="model-block"> 
                <model-viewer exposure="0.5" camera-controls enable-pan shadow-intensity="2" camera-orbit="0deg 75deg 110%" max-camera-orbit="auto auto 200%"
                src="assets/text-to-3d/banana boss, cute, hands and legs.glb">
                </model-viewer>
            </div>

        </div>
        <div class="grid-container-1">
            <a class="mybtn" href="text-conditioned-3D-gallery_0.html" role="button">
             More Results </a>
        </div>
    </div>


    <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">Normal Brush Results</h2>
        <div class="grid-container-4">
            <div>
                <video class="video" id="44" loop playsinline autoPlay muted
                src="assets/refined_mesh/44.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="44_merge"></canvas>
            </div>
            <div>
                <video class="video" id="16" loop playsinline autoPlay muted
                src="assets/refined_mesh/16.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="16_merge"></canvas>
            </div>
            <div>
                <video class="video" id="39" loop playsinline autoPlay muted
                src="assets/refined_mesh/39.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="39_merge"></canvas>
            </div>
            <div>
                <video class="video" id="8" loop playsinline autoPlay muted
                src="assets/refined_mesh/8.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="8_merge"></canvas>
            </div>


        </div>

        <div class="grid-container-1">
            <a class="mybtn" href="normal-brush-gallery_0.html" role="button">
            More Results </a>
        </div>
    </div>


    <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">Method Overview</h2>
        <div class="grid-container-1">
            <img src="assets/images/overview.png">

            <p> Our method first transforms the input single image or text prompt into multi-view images using a multi-view diffusion model.
                These generated multi-view images are then fed into a native 3D diffusion model as conditions to produce a coarse mesh with regular topology. Finally, a
                surface normal-based refinement is employed to improve or edit the coarse geometry, enhancing it with intricate details. The refinement process features two
                key tools: an automatic global refinement and an interactive Magic Brush, which together enable efficient and controllable 3D modeling.
            </p>
        </div>
    </div>




    <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">Related Works</h2>
        <div class="grid-container-1">
	    <p> 
		    <a href="https://neuralcarver.github.io/michelangelo/" target="_blank">Michelangelo</span></a>: 
a Shape-Image-Text-Aligned 3D Variational Auto-Encoder (SITA-VAE) and a conditional Aligned 3D Shape Latent Diffusion Model (ASLDM). Thanks for their open source;<br>
	    	    <a href="https://github.com/CLAY-3D/OpenCLAY" target="_blank">OpenCLAY</a>:
a large-scale generative model composed of a multi-resolution 3D Variational Autoencoder (VAE) and a minimalistic latent 3D Diffusion Transformer (DiT);<br>
		    <a href="https://nju-3dv.github.io/projects/Direct3D/" target="_blank">Direct3D</a>:
a Direct 3D Variational Auto-Encoder (D3D-VAE) and a Direct 3D Diffusion Transformer (D3D-DiT) scalable to in-the-wild input single view images;
	    </p>
        </div>
    </div>

<div class="white_section_nerf grey_container w-container">
<h2 class="grey-heading_nerf">BibTeX</h2>
<div class="bibtex">
    <pre><code>@article{li2024craftsman,
author    = {Weiyu Li and Jiarui Liu and Hongyu Yan and Rui Chen and Yixun Liang and Xuelin Chen and Ping Tan and Xiaoxiao Long},
title     = {CraftsMan3D: High-fidelity Mesh Generation with 3D Native Generation and Interactive Geometry Refiner},
journal   = {arXiv preprint arXiv:2405.14979},
year      = {2024},
}</code></pre>
</div>
</div>

</body>
<footer>
    This project page is inspired by <a href="https://github.com/nerfies/nerfies.github.io">Nerfies.</a>, © Weiyu Li. All rights reserved.
</footer>

</html>
